book_notes = ["My knees went bad when I was a teenager because of a rare condition known as osteochondritis dissecans.\\n\\nJuly 16, 2019", "The orthopedist’s lack of compassion was palpable: in all the months after the surgery, he never contacted me once to see how I was getting along. The physical therapist not only had the medical knowledge and experience to match my condition, but she really cared about me. It’s no wonder that we have an opioid epidemic when it’s a lot quicker and easier for doctors to prescribe narcotics than to listen to and understand patients. Almost anyone with chronic medical conditions has been “roughed up” like I was—it happens all too frequently. I’m fortunate to be inside the medical system, but, as you have seen, the problem is so pervasive that even insider knowledge isn’t necessarily enough to guarantee good care. Artificial intelligence alone is not going to solve this problem on its own. We need humans to kick in. As machines get smarter and take on suitable tasks, humans might actually find it easier to be more humane.\\n\\nJuly 16, 2019", "The key to saving this boy’s life was determining the root cause of his condition. Few hospitals in the world today are sequencing the genomes of sick newborns and employing artificial intelligence to make everything known about the patient and genomics work together. Although very experienced physicians might eventually have hit upon the right course of treatment, machines can do this kind of work far quicker and better than people.\\n\\nJuly 16, 2019", "For all the hype about the use of AI to improve healthcare, had it been applied to this patient’s data and the complete corpus of medical literature, it would have concluded not to do the procedure because there’s no evidence that indicates the opening of a right coronary artery will alleviate symptoms of fatigue—and AI is capable of learning what to do only by examining existing evidence.\\n\\nJuly 16, 2019", "What’s wrong in healthcare today is that it’s missing care. That is, we generally, as doctors, don’t get to really care for patients enough. And patients don’t feel they are cared for. As Francis Peabody wrote in 1927, “The secret of the care of the patient is caring for the patient.” 5 The greatest opportunity offered by AI is not reducing errors or workloads, or even curing cancer: it is the opportunity to restore the precious and time-honored connection and trust—the human touch—between patients and doctors. Not only would we have more time to come together, enabling far deeper communication and compassion, but also we would be able to revamp how we select and train doctors.\\n\\nJuly 20, 2019", "This leveling of the medical knowledge landscape will ultimately lead to a new premium: to find and train doctors who have the highest level of emotional intelligence.\\n\\nJuly 20, 2019", "Because of electronic health records, eye contact between the patient and doctor is limited. Russell Phillips, a Harvard physician said, “The electronic medical record has turned physicians into data entry technicians.” Attending to the keyboard, instead of the patient, is ascribed as a principal reason for the medical profession’s high rates of depression and burnout.\\n\\nJuly 26, 2019", "The use of electronic healthcare records leads to other problems. The information that they contain is often remarkably incomplete and inaccurate. Electronic records are very clunky to use, and most—an average of 80 percent—of each note is simply copied and pasted from a previous note.\\n\\nJuly 26, 2019", "The incompleteness of the records is accentuated by one-off medicine. By “one-off,” I’m not just referring to the brevity or rarity of the interaction. We haven’t had access to patients in their real world, on the go, at work, while asleep. The data doctors access are from the contrived setting of a medical office, constrained by the temporal limits of the visit itself. A patient wearing a patch like I had Robert do is exceedingly rare. For the most part, we have no idea of what any given individual’s real-life medical metrics—such as blood pressure, heart rate and rhythm, or level of anxiety and mood—actually are. In fact, even if we did know this for someone, we wouldn’t have a means to make useful comparisons, as we don’t even yet know what is normal for the population as a whole in a real-world context.\\n\\nJuly 26, 2019", "In the United States, mammography is recommended annually for women in their fifties. The total cost of the screening alone is more than $10 billion per year. Worse, if we consider 10,000 women in their fifties who have mammography each year for ten years, only five (0.05 percent) avoid a breast cancer death, while more than 6,000 (60 percent) will have at least one false positive result. 14 The latter might result in the harm and expense of a number of unnecessary procedures, including biopsies, surgery, radiation, or chemotherapy; at the very least, it results in considerable fear and anxiety.\\n\\nJuly 26, 2019", "A great many of these problems could be avoided—and the tests and procedures could be done much more intelligently—if physicians actually took the time to identify whether a patient was at some risk of the disease they were trying to avoid. One important tool that has widespread awareness in medicine but is nevertheless regularly ignored is Bayes’s theorem, which describes how knowledge about the conditions surrounding a possible event affect the probability that it happens.\\n\\nJuly 29, 2019", "Nevertheless, the idea that a cluster of symptoms can lead to a correct diagnosis seems oversimplified. When listening to patients, it’s abundantly clear that presence of a symptom is not 0 or 1, binary; rather, symptoms are nuanced and colored. For example, a patient suffering aortic dissection might not describe the sensation as “chest pain.” For a heart attack, the patient could show his or her clenched fist (known as Levine’s sign), denoting a sense of pressure not perceived as pain. Or it could be a burning that isn’t felt as either pressure or pain. Further complicating the matter for such diagnostic applications is that not only are symptoms subjective, how they are conveyed by the patient via descriptors, facial expression, and body language is critical and often cannot be readily captured by a few words.\\n\\nAugust 1, 2019", "The difficulty in assembly and aggregation of the data has been underestimated, not just by Watson but all tech companies getting involved with healthcare.\\n\\nAugust 1, 2019", "The Face2Gene app from FDNA is worth highlighting as it can help the diagnosis for more than 4,000 genetic conditions, many of which can be extremely difficult to pinpoint. An example is a child with the rare Coffin-Siris syndrome. The app makes the diagnosis by recognizing unique facial features in seconds, whereas in some families it has taken up to sixteen years of extensive and expensive evaluations for humans to make the same diagnosis. The app’s creators accomplished this by applying deep learning to images of afflicted individuals, identifying the rare but distinctive constellation of facial features that are the hallmark of the syndrome. Already 60 percent of medical geneticists and genetic counselors have used the app. And that’s especially good because its wide use continually expands the knowledge resource to more accurately diagnose an ever-increasing proportion of rare diseases.\\n\\nAugust 1, 2019", "There were vital lessons in AliveCor’s experience for anyone seeking to apply AI to medicine. When I asked Petterson what he learned, he said, “Don’t filter the data too early.… I was at Google. Vic was at Google. Simon was at Google. We have learned this lesson before, but sometimes you have to learn the lesson multiple times. Machine learning tends to work best if you give it enough data and the rawest data you can. Because if you have enough of it, then it should be able to filter out the noise by itself.”\\n\\nAugust 3, 2019", "When you have a dataset of a million entries in medicine, it’s a giant dataset. And so, the order or magnitude that Google works at is not just a thousand times bigger but a million times bigger.” Filtering the data so that a person can manually annotate it is a terrible idea.\\n\\nAugust 3, 2019", "We can see some fundamentals for deep learning algorithmic development. Getting the labeling or ground truths right is critical: the input to the algorithm has to be correct if there’s any chance for an algorithm output to be useful. When the potassium values were not taken close to the time of the ECG, the chance of making an accurate prediction was significantly impaired. Filtering the patient sample to only outpatients—because it seemed at first to the people involved to be the best cohort to analyze—nearly killed the project, as did the human assumption that the valuable input would be in the T wave rather than the whole ECG signal.\\n\\nAugust 3, 2019", "Deep learning AI is all about inputs and outputs. As Andrew Ng, a rock star in AI, puts it, “Input and output mapping is a new superpower.” Algorithms like to eat data, the more the better, but that data needs to include lots of the whole range of values for inputs to get a bull’s-eye for outputs. It reminds me of taking care of patients in the intensive care unit: one of the key metrics to assess every day is how much fluid a patient takes in versus how much urine is made. Without accurate records of inputs and outputs, we might treat the patient improperly, perhaps upping the intravenous fluids or prescribing diuretics. In both cases, bad inputs and outputs can kill a patient.\\n\\nAugust 3, 2019", "exceptional textbook called Deep Learning by Ian Goodfellow, a young, brilliant, staff scientist at Google Brain, and his colleagues.\\n\\nAugust 3, 2019", "Thousands of chest X-rays, read and labeled with diagnoses by expert radiologists, provide the ground truths for the network to learn from (Figure 4.5). Once trained, the network is ready for an unlabeled chest X-ray to be input. The data go through multiple hidden layers of neurons, from five to one thousand, each responding to different features in the X-ray image, such as shapes or edges. As the image (propagated data) goes onto higher layers, the features and structures get more complex. The deeper the network, by number of layers, the more complexity it can draw out of the input image. At the top layer, the neurons have now fully differentiated the features and are ready for output—predicting what the chest X-ray shows, based on its training. 23 DNNs, with this structural backbone, can functionally be regarded as a general-utility, or a general-purpose, technology, much like the steam engine or electricity.\\n\\nOctober 8, 2019", "It took combining DNN (supervised and reinforcement learning) with GOFAI, in the latter case a Monte Carlo tree search. 30 The key winning move (move 37), as it turned out, was viewed as highly creative—despite the fact that a machine made it—and perhaps more importantly, it was made in defiance of human wisdom. 31 That was certainly a monumental AI achievement for such a remarkably complex and ancient game. But it didn’t take long before even that achievement was superseded. In the fall of 2017, AlphaGo Zero, the next iteration of algorithm beyond AlphaGo, took the game world by storm. 32 AlphaGo Zero played millions of games against itself, just starting from random moves. In the Nature paper, “Mastering the Game of Go Without Human Knowledge,” the researchers concluded that “it is possible [for an algorithm] to train to superhuman level, without human examples or guidance, given no knowledge of the domain beyond basic rules.” It was also a stunning example of doing more with less: AlphaGo Zero, in contrast to AlphaGo, had fewer than 5 million training games compared with 30 million, three days of training instead of several months, a single neural network compared with two separate ones, and it performed via a single tensor processing unit (TPU) chip\\n\\nOctober 8, 2019", "ImageNet exemplified an adage about AI: datasets—not algorithms—might be the key limiting factor of human-level artificial intelligence. 39 When Fei-Fei Li, a computer scientist now at Stanford and half time at Google, started ImageNet in 2007, she bucked the idea that algorithms ideally needed nurturing from Big Data and instead pursued the in-depth annotation of images. She recognized it wasn’t about Big Data; it was about carefully, extensively labeled Big Data. A few years ago, she said, “I consider the pixel data in images and video to be the dark matter of the Internet.” 40 Many different convolutional DNNs were used to classify the images with annual ImageNet Challenge contests to recognize the best (such as AlexNet, GoogleNet, VGG Net, and ResNet). Figure 4.6 shows the progress in reducing the error rate over several years, with ImageNet wrapping up in 2017, with significantly better than human performance in image recognition. The error rate fell from 30 percent in 2010 to 4 percent in 2016. Li’s 2015 TED Talk “How We’re Teaching Computers to Understand Pictures” has been viewed more than 2 million times, and it’s one of my favorites\\n\\nOctober 8, 2019", "Neural networks benefit from optimal quality and quantity of the data that they are trained with and that they use to make predictions. Most AI work to date has been with structured data (such as images, speech, and games) that are highly organized, in a defined format, readily searchable, simple to deal with, store and query, and fully analyzable. Unfortunately, much data is not labeled or annotated, “clean,” or structured. In medicine, there’s a plethora of unstructured data such as free text in electronic medical records. With rare exceptions, AI, to date, has used supervised learning, which strongly requires establishing “ground truths” for training. Any inaccurate labeling or truths can render the network output nonsensical. For example, doctor interpretation of scans often lacks concordance, making ground truths shaky. Cleaning the data means either getting all the incomplete, irrelevant, corrupt, inaccurate, incorrect stuff out or modifying it to warrant inclusion.\\n\\nOctober 11, 2019", "The progress that is being made in AI should not bypass the time-accepted validation of the expert peer-review process. Further, the majority of medical studies published to date are retrospective, performed in silico, yet to be prospectively validated in a real-world, clinical setting.\\n\\nOctober 11, 2019", "Dudley led his team on a project called Deep Patient to see whether the data from electronic medical records could be used to predict the occurrence of seventy-eight diseases. When the neural network was used on more than 700,000 Mount Sinai patients, it was able to predict, using unsupervised learning from raw medical record data (with stacked denoising autoencoders), the probability and timing of onset of schizophrenia (among other conditions), something that is extremely hard for doctors to predict. And Dudley said something that sums up the AI black box problem: “We can build these models, but we don’t know how they work.”\\n\\nOctober 11, 201"]


# for each highlight, get rid of the date.  Date range: May 17-21, 2017
notes_sans_dates = book_notes.map do |note|
  note.scan(/(?<=)(.*?)(?=\\n\\n)/).flatten.join
end

# get rid of the bookmarks
@book_highlights = notes_sans_dates.delete_if {|element| element==""}
@author = 'Eric Topol'
@book_title = 'Deep Medicine'
@url = 'https://www.amazon.com/Deep-Medicine-Artificial-Intelligence-Healthcare/dp/1541644638/ref=sr_1_2?keywords=deep+medicine&qid=1575823165&sr=8-2'
